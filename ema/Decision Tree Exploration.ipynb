{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "clean_data = scipy.io.loadmat('Data/cleandata_students.mat')\n",
    "noisy_data = scipy.io.loadmat('Data/noisydata_students.mat')\n",
    "\n",
    "# clean_X and noisy_X are numpy matrixes with dimensions (# of training examples, number of features) containing training data\n",
    "clean_X = clean_data['x']\n",
    "noisy_X = noisy_data['x']\n",
    "\n",
    "# clean_Y and noisy_Y are numpy matrixes with dimensions (# of training examples, 1) \n",
    "# clean_Y[k][0] contains the target emotion for training example k\n",
    "clean_Y = clean_data['y']\n",
    "noisy_Y = noisy_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "node = {\n",
    "    kids: [], # 1x2 array containing left and right children\n",
    "    op: number, # index of the attribute the node is splitting on\n",
    "    class: number, # only for leaf node: index of predicted class for this path\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def create_binary_decision_tree(emotion_number, X, y):\n",
    "    root = helper([0..len(X[0])], X, y)\n",
    "    \n",
    "def helper(predictors, remaining_X, remaining_y):    \n",
    "    # Out of all predictors remaining_X_j and values s, we need to find j and s such that entropy is minimized\n",
    "    # In this case, since the predictors are binary, we don't need to find s since we only have one choice of branching\n",
    "    j = get_best_predictor(predictors, remaining_X, remaining_y)\n",
    "    # Now all training examples with remaining_X_j = 0 will belong to the left subtree, and remaining_X_j = 1 to the right subtree\n",
    "    left_X = filter(remaining_X, lambda example: example[j] == 0)\n",
    "    left_y = filter(remaining_y, lambda example: example[j] == 0)\n",
    "    \n",
    "    right_X = filter(remaining_X, lambda example: example[j] == 1)\n",
    "    right_y = filter(remaining_y, lambda example: example[j] == 1)\n",
    "    \n",
    "    remaining_predictors = list(predictors)\n",
    "    remaining_predictors.remove(j)\n",
    "    \n",
    "    left_node = helper(remaining_predictors, left_X, left_y)\n",
    "    right_node = helper(remaining_predictors, right_X, right_y)\n",
    "    \n",
    "    current_node = {\n",
    "        'kids': [left_node, roght_node]\n",
    "        'op': j\n",
    "    }\n",
    "    \n",
    "    return current_node\n",
    "    \n",
    "\"\"\" \n",
    "Return the predictor among predictors which maximizes the information gain for data X and y\n",
    "\"\"\"\n",
    "def get_best_predictor(predictors, X, Y):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
